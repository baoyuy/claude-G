const express = require('express')
const fs = require('fs')
const path = require('path')
const axios = require('axios')
const claudeCodeHeadersService = require('../../services/claudeCodeHeadersService')
const claudeAccountService = require('../../services/claudeAccountService')
const redis = require('../../models/redis')
const { authenticateAdmin } = require('../../middleware/auth')
const logger = require('../../utils/logger')
const config = require('../../../config/config')

const router = express.Router()

// ==================== Claude Code Headers ç®¡ç† ====================

// è·å–æ‰€æœ‰ Claude Code headers
router.get('/claude-code-headers', authenticateAdmin, async (req, res) => {
  try {
    const allHeaders = await claudeCodeHeadersService.getAllAccountHeaders()

    // è·å–æ‰€æœ‰ Claude è´¦å·ä¿¡æ¯
    const accounts = await claudeAccountService.getAllAccounts()
    const accountMap = {}
    accounts.forEach((account) => {
      accountMap[account.id] = account.name
    })

    // æ ¼å¼åŒ–è¾“å‡º
    const formattedData = Object.entries(allHeaders).map(([accountId, data]) => ({
      accountId,
      accountName: accountMap[accountId] || 'Unknown',
      version: data.version,
      userAgent: data.headers['user-agent'],
      updatedAt: data.updatedAt,
      headers: data.headers
    }))

    return res.json({
      success: true,
      data: formattedData
    })
  } catch (error) {
    logger.error('âŒ Failed to get Claude Code headers:', error)
    return res
      .status(500)
      .json({ error: 'Failed to get Claude Code headers', message: error.message })
  }
})

// ğŸ—‘ï¸ æ¸…é™¤æŒ‡å®šè´¦å·çš„ Claude Code headers
router.delete('/claude-code-headers/:accountId', authenticateAdmin, async (req, res) => {
  try {
    const { accountId } = req.params
    await claudeCodeHeadersService.clearAccountHeaders(accountId)

    return res.json({
      success: true,
      message: `Claude Code headers cleared for account ${accountId}`
    })
  } catch (error) {
    logger.error('âŒ Failed to clear Claude Code headers:', error)
    return res
      .status(500)
      .json({ error: 'Failed to clear Claude Code headers', message: error.message })
  }
})

// ==================== ç³»ç»Ÿæ›´æ–°æ£€æŸ¥ ====================

const { exec } = require('child_process')
const util = require('util')
const execPromise = util.promisify(exec)

// GitHub ä»“åº“é…ç½®
const GITHUB_REPO = 'baoyuy/claude-G'
const GITHUB_BRANCH = 'main'

// ç‰ˆæœ¬æ¯”è¾ƒå‡½æ•°
function compareVersions(current, latest) {
  const parseVersion = (v) => {
    const clean = String(v).replace(/^v/, '')
    const parts = clean.split('.').map(Number)
    return {
      major: parts[0] || 0,
      minor: parts[1] || 0,
      patch: parts[2] || 0
    }
  }

  const currentV = parseVersion(current)
  const latestV = parseVersion(latest)

  if (currentV.major !== latestV.major) {
    return currentV.major - latestV.major
  }
  if (currentV.minor !== latestV.minor) {
    return currentV.minor - latestV.minor
  }
  return currentV.patch - latestV.patch
}

// æ£€æŸ¥æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
async function isGitRepo(cwd) {
  try {
    await execPromise('git rev-parse --git-dir', { cwd, timeout: 5000 })
    return true
  } catch {
    return false
  }
}

// è·å–æœ¬åœ° Git commit hash
async function getLocalCommitHash(cwd) {
  try {
    const { stdout } = await execPromise('git rev-parse HEAD', { cwd, timeout: 5000 })
    return stdout.trim()
  } catch {
    return null
  }
}

// è·å–è¿œç¨‹æœ€æ–° commit hashï¼ˆé€šè¿‡ GitHub APIï¼‰
async function getRemoteCommitHash() {
  try {
    const response = await axios.get(`https://api.github.com/repos/${GITHUB_REPO}/commits/${GITHUB_BRANCH}`, {
      headers: {
        Accept: 'application/vnd.github.v3+json',
        'User-Agent': 'Claude-Relay-Service'
      },
      timeout: 15000
    })
    return {
      sha: response.data.sha,
      message: response.data.commit.message,
      date: response.data.commit.committer.date,
      author: response.data.commit.author.name
    }
  } catch (error) {
    logger.warn('âš ï¸ Failed to get remote commit from GitHub API:', error.message)
    return null
  }
}

// è·å–è¿œç¨‹æœ€æ–° commitï¼ˆé€šè¿‡ git fetchï¼‰
async function getRemoteCommitViaGit(cwd) {
  try {
    // å…ˆ fetch è¿œç¨‹æ›´æ–°
    await execPromise(`git fetch origin ${GITHUB_BRANCH}`, { cwd, timeout: 30000 })
    // è·å–è¿œç¨‹åˆ†æ”¯çš„æœ€æ–° commit
    const { stdout } = await execPromise(`git rev-parse origin/${GITHUB_BRANCH}`, { cwd, timeout: 5000 })
    return stdout.trim()
  } catch (error) {
    logger.warn('âš ï¸ Failed to fetch remote commit via git:', error.message)
    return null
  }
}

// è·å–æœ€è¿‘çš„ commits åˆ—è¡¨ï¼ˆç”¨äºæ˜¾ç¤ºæ›´æ–°å†…å®¹ï¼‰
async function getRecentCommits(since) {
  try {
    const response = await axios.get(`https://api.github.com/repos/${GITHUB_REPO}/commits`, {
      params: {
        sha: GITHUB_BRANCH,
        since: since,
        per_page: 20
      },
      headers: {
        Accept: 'application/vnd.github.v3+json',
        'User-Agent': 'Claude-Relay-Service'
      },
      timeout: 15000
    })
    return response.data.map((c) => ({
      sha: c.sha.substring(0, 7),
      message: c.commit.message.split('\n')[0],
      date: c.commit.committer.date,
      author: c.commit.author.name
    }))
  } catch {
    return []
  }
}

router.get('/check-updates', authenticateAdmin, async (req, res) => {
  const projectRoot = path.join(__dirname, '../../..')
  const versionPath = path.join(projectRoot, 'VERSION')

  // è¯»å–å½“å‰ç‰ˆæœ¬å·
  let currentVersion = '1.0.0'
  try {
    currentVersion = fs.readFileSync(versionPath, 'utf8').trim()
  } catch (err) {
    logger.warn('âš ï¸ Could not read VERSION file:', err.message)
  }

  try {
    // æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
    const cacheKey = 'version_check_cache_v2'
    if (!req.query.force) {
      const cached = await redis.getClient().get(cacheKey)
      if (cached) {
        const cachedData = JSON.parse(cached)
        const cacheAge = Date.now() - cachedData.timestamp
        // ç¼“å­˜æœ‰æ•ˆæœŸ 10 åˆ†é’Ÿ
        if (cacheAge < 600000) {
          return res.json({
            success: true,
            data: {
              ...cachedData.data,
              current: currentVersion,
              cached: true
            }
          })
        }
      }
    }

    // æ£€æŸ¥æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
    const isGit = await isGitRepo(projectRoot)
    const isDocker = fs.existsSync('/.dockerenv')

    let localCommit = null
    let remoteCommit = null
    let hasUpdate = false
    let updateMethod = 'unknown'
    let recentCommits = []

    if (isGit && !isDocker) {
      // Git æ¨¡å¼ï¼šé€šè¿‡ git å‘½ä»¤æ£€æŸ¥
      updateMethod = 'git'
      localCommit = await getLocalCommitHash(projectRoot)

      // ä¼˜å…ˆä½¿ç”¨ git fetch è·å–è¿œç¨‹ commit
      const remoteCommitHash = await getRemoteCommitViaGit(projectRoot)
      if (remoteCommitHash) {
        remoteCommit = { sha: remoteCommitHash }
      } else {
        // å›é€€åˆ° GitHub API
        remoteCommit = await getRemoteCommitHash()
      }

      if (localCommit && remoteCommit) {
        hasUpdate = localCommit !== remoteCommit.sha
      }
    } else {
      // é Git æ¨¡å¼ï¼ˆDocker æˆ–ç›´æ¥ä¸‹è½½ï¼‰ï¼šé€šè¿‡ GitHub API æ£€æŸ¥
      updateMethod = isDocker ? 'docker' : 'tarball'
      remoteCommit = await getRemoteCommitHash()

      // å°è¯•è¯»å–æœ¬åœ°è®°å½•çš„ commit hash
      const commitFilePath = path.join(projectRoot, '.git_commit')
      try {
        localCommit = fs.readFileSync(commitFilePath, 'utf8').trim()
      } catch {
        localCommit = null
      }

      if (remoteCommit) {
        hasUpdate = !localCommit || localCommit !== remoteCommit.sha
      }
    }

    // å¦‚æœæœ‰æ›´æ–°ï¼Œè·å–æœ€è¿‘çš„ commits
    if (hasUpdate && localCommit) {
      // è·å–æœ¬åœ° commit çš„æ—¶é—´
      try {
        const localCommitInfo = await axios.get(`https://api.github.com/repos/${GITHUB_REPO}/commits/${localCommit}`, {
          headers: {
            Accept: 'application/vnd.github.v3+json',
            'User-Agent': 'Claude-Relay-Service'
          },
          timeout: 10000
        })
        const sinceDate = localCommitInfo.data.commit.committer.date
        recentCommits = await getRecentCommits(sinceDate)
        // è¿‡æ»¤æ‰æœ¬åœ°å·²æœ‰çš„ commit
        recentCommits = recentCommits.filter((c) => !localCommit.startsWith(c.sha))
      } catch {
        // å¿½ç•¥é”™è¯¯
      }
    }

    const responseData = {
      current: currentVersion,
      latest: remoteCommit ? currentVersion : currentVersion, // ç‰ˆæœ¬å·ä¿æŒä¸å˜ï¼Œç”¨ commit åˆ¤æ–­
      hasUpdate,
      updateMethod,
      localCommit: localCommit ? localCommit.substring(0, 7) : null,
      remoteCommit: remoteCommit ? remoteCommit.sha.substring(0, 7) : null,
      isDocker,
      isGitRepo: isGit,
      releaseInfo: {
        name: hasUpdate ? 'æœ‰æ–°çš„æ›´æ–°å¯ç”¨' : 'å½“å‰å·²æ˜¯æœ€æ–°ç‰ˆæœ¬',
        body: hasUpdate
          ? recentCommits.length > 0
            ? `æœ€è¿‘ ${recentCommits.length} ä¸ªæ›´æ–°:\n${recentCommits.map((c) => `â€¢ ${c.sha} ${c.message}`).join('\n')}`
            : `è¿œç¨‹æœ‰æ–°çš„æäº¤ (${remoteCommit?.sha?.substring(0, 7)})`
          : 'æ²¡æœ‰æ–°çš„æ›´æ–°',
        publishedAt: remoteCommit?.date || new Date().toISOString(),
        htmlUrl: `https://github.com/${GITHUB_REPO}/commits/${GITHUB_BRANCH}`
      },
      recentCommits
    }

    // ç¼“å­˜ç»“æœ
    await redis.getClient().set(
      cacheKey,
      JSON.stringify({
        data: responseData,
        timestamp: Date.now()
      }),
      'EX',
      600
    )

    return res.json({
      success: true,
      data: responseData
    })
  } catch (error) {
    logger.error('âŒ Failed to check for updates:', error.message)

    return res.json({
      success: true,
      data: {
        current: currentVersion,
        latest: currentVersion,
        hasUpdate: false,
        error: true,
        warning: error.message || 'Failed to check for updates',
        releaseInfo: {
          name: 'æ£€æŸ¥æ›´æ–°å¤±è´¥',
          body: `æ— æ³•æ£€æŸ¥æ›´æ–°: ${error.message}`,
          publishedAt: new Date().toISOString(),
          htmlUrl: `https://github.com/${GITHUB_REPO}`
        }
      }
    })
  }
})

// ==================== OEM è®¾ç½®ç®¡ç† ====================

// è·å–OEMè®¾ç½®ï¼ˆå…¬å¼€æ¥å£ï¼Œç”¨äºæ˜¾ç¤ºï¼‰
// æ³¨æ„ï¼šè¿™ä¸ªç«¯ç‚¹æ²¡æœ‰ authenticateAdmin ä¸­é—´ä»¶ï¼Œå› ä¸ºå‰ç«¯ç™»å½•é¡µä¹Ÿéœ€è¦è®¿é—®
router.get('/oem-settings', async (req, res) => {
  try {
    const client = redis.getClient()
    const oemSettings = await client.get('oem:settings')

    // é»˜è®¤è®¾ç½®
    const defaultSettings = {
      siteName: 'Claude Relay Service',
      siteIcon: '',
      siteIconData: '', // Base64ç¼–ç çš„å›¾æ ‡æ•°æ®
      showAdminButton: true, // æ˜¯å¦æ˜¾ç¤ºç®¡ç†åå°æŒ‰é’®
      purchaseKeyUrl: '', // è´­ä¹°å¯†é’¥é“¾æ¥
      apiStatsNotice: {
        enabled: false,
        title: '',
        content: ''
      },
      updatedAt: new Date().toISOString()
    }

    let settings = defaultSettings
    if (oemSettings) {
      try {
        settings = { ...defaultSettings, ...JSON.parse(oemSettings) }
      } catch (err) {
        logger.warn('âš ï¸ Failed to parse OEM settings, using defaults:', err.message)
      }
    }

    // æ·»åŠ  LDAP å¯ç”¨çŠ¶æ€åˆ°å“åº”ä¸­
    return res.json({
      success: true,
      data: {
        ...settings,
        ldapEnabled: config.ldap && config.ldap.enabled === true
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to get OEM settings:', error)
    return res.status(500).json({ error: 'Failed to get OEM settings', message: error.message })
  }
})

// æ›´æ–°OEMè®¾ç½®
router.put('/oem-settings', authenticateAdmin, async (req, res) => {
  try {
    const { siteName, siteIcon, siteIconData, showAdminButton, purchaseKeyUrl, apiStatsNotice } = req.body

    // éªŒè¯è¾“å…¥
    if (!siteName || typeof siteName !== 'string' || siteName.trim().length === 0) {
      return res.status(400).json({ error: 'Site name is required' })
    }

    if (siteName.length > 100) {
      return res.status(400).json({ error: 'Site name must be less than 100 characters' })
    }

    // éªŒè¯å›¾æ ‡æ•°æ®å¤§å°ï¼ˆå¦‚æœæ˜¯base64ï¼‰
    if (siteIconData && siteIconData.length > 500000) {
      // çº¦375KB
      return res.status(400).json({ error: 'Icon file must be less than 350KB' })
    }

    // éªŒè¯å›¾æ ‡URLï¼ˆå¦‚æœæä¾›ï¼‰
    if (siteIcon && !siteIconData) {
      // ç®€å•éªŒè¯URLæ ¼å¼
      try {
        new URL(siteIcon)
      } catch (err) {
        return res.status(400).json({ error: 'Invalid icon URL format' })
      }
    }

    const settings = {
      siteName: siteName.trim(),
      siteIcon: (siteIcon || '').trim(),
      siteIconData: (siteIconData || '').trim(), // Base64æ•°æ®
      showAdminButton: showAdminButton !== false, // é»˜è®¤ä¸ºtrue
      purchaseKeyUrl: (purchaseKeyUrl || '').trim(), // è´­ä¹°å¯†é’¥é“¾æ¥
      apiStatsNotice: {
        enabled: apiStatsNotice?.enabled === true,
        title: (apiStatsNotice?.title || '').trim().slice(0, 100),
        content: (apiStatsNotice?.content || '').trim().slice(0, 2000)
      },
      updatedAt: new Date().toISOString()
    }

    const client = redis.getClient()
    await client.set('oem:settings', JSON.stringify(settings))

    logger.info(`âœ… OEM settings updated: ${siteName}`)

    return res.json({
      success: true,
      message: 'OEM settings updated successfully',
      data: settings
    })
  } catch (error) {
    logger.error('âŒ Failed to update OEM settings:', error)
    return res.status(500).json({ error: 'Failed to update OEM settings', message: error.message })
  }
})

// ==================== Claude Code ç‰ˆæœ¬ç®¡ç† ====================

router.get('/claude-code-version', authenticateAdmin, async (req, res) => {
  try {
    const CACHE_KEY = 'claude_code_user_agent:daily'

    // è·å–ç¼“å­˜çš„ç»Ÿä¸€User-Agent
    const unifiedUserAgent = await redis.client.get(CACHE_KEY)
    const ttl = unifiedUserAgent ? await redis.client.ttl(CACHE_KEY) : 0

    res.json({
      success: true,
      userAgent: unifiedUserAgent,
      isActive: !!unifiedUserAgent,
      ttlSeconds: ttl,
      lastUpdated: unifiedUserAgent ? new Date().toISOString() : null
    })
  } catch (error) {
    logger.error('âŒ Get unified Claude Code User-Agent error:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to get User-Agent information',
      error: error.message
    })
  }
})

// ğŸ—‘ï¸ æ¸…é™¤ç»Ÿä¸€Claude Code User-Agentç¼“å­˜
router.post('/claude-code-version/clear', authenticateAdmin, async (req, res) => {
  try {
    const CACHE_KEY = 'claude_code_user_agent:daily'

    // åˆ é™¤ç¼“å­˜çš„ç»Ÿä¸€User-Agent
    await redis.client.del(CACHE_KEY)

    logger.info(`ğŸ—‘ï¸ Admin manually cleared unified Claude Code User-Agent cache`)

    res.json({
      success: true,
      message: 'Unified User-Agent cache cleared successfully'
    })
  } catch (error) {
    logger.error('âŒ Clear unified User-Agent cache error:', error)
    res.status(500).json({
      success: false,
      message: 'Failed to clear cache',
      error: error.message
    })
  }
})

// ==================== ç³»ç»Ÿæ›´æ–°æ‰§è¡Œ ====================

// æ‰§è¡Œç³»ç»Ÿæ›´æ–°ï¼ˆæ”¹è¿›ç‰ˆï¼šæ”¯æŒ stashã€fetchã€reset æ¨¡å¼ï¼‰
router.post('/perform-update', authenticateAdmin, async (req, res) => {
  const projectRoot = path.join(__dirname, '../../..')

  try {
    logger.info('ğŸ”„ Starting system update...')

    // æ£€æŸ¥æ˜¯å¦åœ¨ Docker ç¯å¢ƒä¸­
    const isDocker = fs.existsSync('/.dockerenv')

    if (isDocker) {
      // Docker ç¯å¢ƒï¼šè¿”å›æ›´æ–°æŒ‡ä»¤
      return res.json({
        success: true,
        isDocker: true,
        message: 'Docker ç¯å¢ƒæ£€æµ‹åˆ°ï¼Œè¯·åœ¨å®¿ä¸»æœºæ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ›´æ–°ï¼š',
        commands: ['cd /path/to/claude-G', 'docker-compose pull', 'docker-compose up -d'],
        hint: 'æˆ–è€…ä½¿ç”¨ä¸€é”®æ›´æ–°è„šæœ¬: curl -fsSL https://raw.githubusercontent.com/baoyuy/claude-G/main/scripts/update.sh | bash'
      })
    }

    // æ£€æŸ¥æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
    const isGit = await isGitRepo(projectRoot)
    if (!isGit) {
      return res.status(400).json({
        success: false,
        error: 'å½“å‰ç›®å½•ä¸æ˜¯ Git ä»“åº“',
        message: 'è¯·ä½¿ç”¨ä¸€é”®éƒ¨ç½²è„šæœ¬é‡æ–°å®‰è£…ï¼Œæˆ–æ‰‹åŠ¨æ‰§è¡Œ git clone'
      })
    }

    const updateSteps = []

    // Step 1: æ£€æŸ¥å¹¶ stash æœ¬åœ°ä¿®æ”¹
    logger.info('ğŸ“‹ Checking for local changes...')
    try {
      const { stdout: statusOutput } = await execPromise('git status --porcelain', {
        cwd: projectRoot,
        timeout: 10000
      })

      if (statusOutput.trim()) {
        logger.info('ğŸ“¦ Stashing local changes...')
        await execPromise('git stash push -m "Auto stash before update"', {
          cwd: projectRoot,
          timeout: 30000
        })
        updateSteps.push('å·²æš‚å­˜æœ¬åœ°ä¿®æ”¹')
      }
    } catch (stashErr) {
      logger.warn('âš ï¸ Stash warning:', stashErr.message)
    }

    // Step 2: Fetch è¿œç¨‹æ›´æ–°
    logger.info('ğŸ“¥ Fetching remote updates...')
    try {
      await execPromise(`git fetch origin ${GITHUB_BRANCH}`, {
        cwd: projectRoot,
        timeout: 60000
      })
      updateSteps.push('å·²è·å–è¿œç¨‹æ›´æ–°')
    } catch (fetchErr) {
      logger.error('âŒ Fetch failed:', fetchErr.message)
      return res.status(500).json({
        success: false,
        error: 'Fetch failed',
        message: `æ— æ³•è·å–è¿œç¨‹æ›´æ–°: ${fetchErr.message}`
      })
    }

    // Step 3: è·å–æœ¬åœ°å’Œè¿œç¨‹ commit
    const localCommit = await getLocalCommitHash(projectRoot)
    let remoteCommit = null
    try {
      const { stdout } = await execPromise(`git rev-parse origin/${GITHUB_BRANCH}`, {
        cwd: projectRoot,
        timeout: 5000
      })
      remoteCommit = stdout.trim()
    } catch {
      remoteCommit = null
    }

    if (!remoteCommit) {
      return res.status(500).json({
        success: false,
        error: 'æ— æ³•è·å–è¿œç¨‹ç‰ˆæœ¬ä¿¡æ¯'
      })
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    if (localCommit === remoteCommit) {
      return res.json({
        success: true,
        message: 'å½“å‰å·²æ˜¯æœ€æ–°ç‰ˆæœ¬',
        updated: false,
        localCommit: localCommit.substring(0, 7),
        remoteCommit: remoteCommit.substring(0, 7)
      })
    }

    // Step 4: æ‰§è¡Œæ›´æ–°ï¼ˆä½¿ç”¨ reset --hard ç¡®ä¿å®Œå…¨åŒæ­¥ï¼‰
    logger.info(`ğŸ”„ Updating from ${localCommit.substring(0, 7)} to ${remoteCommit.substring(0, 7)}...`)
    try {
      await execPromise(`git reset --hard origin/${GITHUB_BRANCH}`, {
        cwd: projectRoot,
        timeout: 60000
      })
      updateSteps.push(`å·²æ›´æ–°åˆ° ${remoteCommit.substring(0, 7)}`)
    } catch (resetErr) {
      logger.error('âŒ Reset failed:', resetErr.message)
      return res.status(500).json({
        success: false,
        error: 'Reset failed',
        message: `æ›´æ–°å¤±è´¥: ${resetErr.message}`
      })
    }

    // Step 5: æ£€æŸ¥ package.json æ˜¯å¦æœ‰å˜åŒ–ï¼Œå†³å®šæ˜¯å¦éœ€è¦ npm install
    let needsNpmInstall = false
    try {
      const { stdout: diffOutput } = await execPromise(`git diff ${localCommit}..${remoteCommit} --name-only`, {
        cwd: projectRoot,
        timeout: 10000
      })
      needsNpmInstall = diffOutput.includes('package.json') || diffOutput.includes('package-lock.json')
    } catch {
      // ä¿å®ˆèµ·è§ï¼Œå¦‚æœæ£€æŸ¥å¤±è´¥å°±æ‰§è¡Œ npm install
      needsNpmInstall = true
    }

    if (needsNpmInstall) {
      logger.info('ğŸ“¦ Installing dependencies...')
      try {
        await execPromise('npm install --production=false', {
          cwd: projectRoot,
          timeout: 180000
        })
        updateSteps.push('å·²æ›´æ–°ä¾èµ–')
      } catch (npmErr) {
        logger.warn('âš ï¸ npm install warning:', npmErr.message)
        updateSteps.push('ä¾èµ–æ›´æ–°å¯èƒ½ä¸å®Œæ•´ï¼Œå»ºè®®æ‰‹åŠ¨æ‰§è¡Œ npm install')
      }
    }

    // Step 6: æ„å»ºå‰ç«¯ï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
    let needsFrontendBuild = false
    try {
      const { stdout: webDiffOutput } = await execPromise(`git diff ${localCommit}..${remoteCommit} --name-only -- web/`, {
        cwd: projectRoot,
        timeout: 10000
      })
      needsFrontendBuild = webDiffOutput.trim().length > 0
    } catch {
      needsFrontendBuild = true
    }

    if (needsFrontendBuild) {
      logger.info('ğŸ”¨ Building frontend...')
      try {
        await execPromise('npm run build:web', {
          cwd: projectRoot,
          timeout: 300000
        })
        updateSteps.push('å·²é‡æ–°æ„å»ºå‰ç«¯')
      } catch (buildErr) {
        logger.warn('âš ï¸ Frontend build warning:', buildErr.message)
        updateSteps.push('å‰ç«¯æ„å»ºå¯èƒ½å¤±è´¥ï¼Œå»ºè®®æ‰‹åŠ¨æ‰§è¡Œ npm run build:web')
      }
    }

    // æ¸…é™¤æ›´æ–°æ£€æŸ¥ç¼“å­˜
    try {
      await redis.getClient().del('version_check_cache_v2')
    } catch {
      // ignore
    }

    logger.info('âœ… System update completed successfully')

    return res.json({
      success: true,
      message: 'æ›´æ–°å®Œæˆï¼Œè¯·é‡å¯æœåŠ¡ä»¥ç”Ÿæ•ˆ',
      updated: true,
      previousCommit: localCommit.substring(0, 7),
      currentCommit: remoteCommit.substring(0, 7),
      steps: updateSteps,
      needRestart: true
    })
  } catch (error) {
    logger.error('âŒ System update failed:', error)
    return res.status(500).json({
      success: false,
      error: 'Update failed',
      message: error.message
    })
  }
})

// é‡å¯æœåŠ¡
router.post('/restart-service', authenticateAdmin, async (req, res) => {
  try {
    logger.info('ğŸ”„ Restarting service...')

    // å‘é€å“åº”åå†é‡å¯
    res.json({
      success: true,
      message: 'æœåŠ¡å³å°†é‡å¯...'
    })

    // å»¶è¿Ÿ1ç§’åé‡å¯ï¼Œç¡®ä¿å“åº”å·²å‘é€
    setTimeout(() => {
      logger.info('ğŸ‘‹ Service restarting now...')
      process.exit(0) // PM2æˆ–Dockerä¼šè‡ªåŠ¨é‡å¯
    }, 1000)

  } catch (error) {
    logger.error('âŒ Service restart failed:', error)
    return res.status(500).json({
      success: false,
      error: 'Restart failed',
      message: error.message
    })
  }
})

// è·å–ç³»ç»Ÿä¿¡æ¯
router.get('/system-info', authenticateAdmin, async (req, res) => {
  try {
    const versionPath = path.join(__dirname, '../../../VERSION')
    let currentVersion = '1.0.0'
    try {
      currentVersion = fs.readFileSync(versionPath, 'utf8').trim()
    } catch (err) {
      // ignore
    }

    const isDocker = fs.existsSync('/.dockerenv')
    const uptime = process.uptime()
    const memUsage = process.memoryUsage()

    return res.json({
      success: true,
      data: {
        version: currentVersion,
        isDocker,
        nodeVersion: process.version,
        platform: process.platform,
        uptime: Math.floor(uptime),
        memory: {
          used: Math.round(memUsage.heapUsed / 1024 / 1024),
          total: Math.round(memUsage.heapTotal / 1024 / 1024)
        },
        pid: process.pid
      }
    })
  } catch (error) {
    logger.error('âŒ Failed to get system info:', error)
    return res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

module.exports = router
